{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import shutil\n",
    "# import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import cv2\n",
    "# import tensorflow as tf\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "from Densenet import CustomDenseNet121\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirst,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    ToTensor,\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.utils import set_determinism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\Chirag C\\vit\\docs\\potato\\Potato_Leaf'\n",
    "class_names = sorted([x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x))])\n",
    "num_class = len(class_names)\n",
    "valid_frac, test_frac = 0.1, 0.1\n",
    "image_files = [[os.path.join(data_dir, class_name, x)\n",
    "                for x in os.listdir(os.path.join(data_dir, class_name))]\n",
    "               for class_name in class_names]\n",
    "image_file_list = []\n",
    "image_label_list = []\n",
    "for i, class_name in enumerate(class_names):\n",
    "    image_file_list.extend(image_files[i])\n",
    "    image_label_list.extend([i] * len(image_files[i]))\n",
    "for i in range(len(image_file_list)):\n",
    "    cat = cv2.imread(image_file_list[i])\n",
    "    width, height = int(500), int(500)\n",
    "    resized_cat = cv2.resize(cat, (width, height), interpolation = cv2.INTER_AREA,)\n",
    "    cv2.imwrite(image_file_list[i], resized_cat)\n",
    "\n",
    "num_total = len(image_label_list)\n",
    "image_width, image_height = Image.open(image_file_list[504]).size\n",
    "\n",
    "print('Total image count:', num_total)\n",
    "print(\"Image dimensions:\", image_width, \"x\", image_height)\n",
    "print(\"Label names:\", class_names)\n",
    "print(\"Label counts:\", [len(image_files[i]) for i in range(num_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i,k in enumerate(np.random.randint(num_total, size=9)):\n",
    "    im = Image.open(image_file_list[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xlabel(class_names[image_label_list[k]])\n",
    "    plt.imshow(arr, cmap='gray', vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY, valX, valY, testX, testY = [], [], [], [], [], []\n",
    "for i in range(len(image_file_list)):\n",
    "    rann = np.random.random()\n",
    "    if rann < valid_frac:\n",
    "        valX.append(image_file_list[i])\n",
    "        valY.append(image_label_list[i])\n",
    "    elif rann < test_frac + valid_frac:\n",
    "        testX.append(image_file_list[i])\n",
    "        testY.append(image_label_list[i])\n",
    "    else:\n",
    "        trainX.append(image_file_list[i])\n",
    "        trainY.append(image_label_list[i])\n",
    "print(\"Training count =\", len(trainX), \"Validation count =\", len(valX), \"Test count =\", len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    EnsureChannelFirst(),\n",
    "    ScaleIntensity(),\n",
    "    RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
    "    RandFlip(spatial_axis=0, prob=0.5),\n",
    "    RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5, keep_size=True),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "val_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    EnsureChannelFirst(),\n",
    "    ScaleIntensity(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "act = Activations(softmax=True)\n",
    "to_onehot = AsDiscrete(to_onehot=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomDenseNet121(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=num_class\n",
    ").to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "epoch_num = 2\n",
    "val_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scann(Dataset):\n",
    "    \n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "train_ds = Scann(trainX, trainY, train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=10, shuffle=True)\n",
    "\n",
    "val_ds = Scann(valX, valY, val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=10)\n",
    "\n",
    "test_ds = Scann(testX, testY, val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(parameters):\n",
    "    model = CustomDenseNet121(\n",
    "        spatial_dims=2,\n",
    "        in_channels=3,\n",
    "        out_channels=num_class\n",
    "    ).to(device)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    for epoch in range(epoch_num):\n",
    "        model.train()\n",
    "        for batch_data in train_loader:\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    model.eval()\n",
    "    test_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            outputs = model(inputs)\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            correct_predictions = torch.sum(predictions == labels)\n",
    "            test_accuracy += correct_predictions.item()\n",
    "    \n",
    "    test_accuracy /= len(test_loader.dataset)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "auc_metric = ROCAUCMetric()\n",
    "metric_values = list()\n",
    "for epoch in range(epoch_num):\n",
    "    print('-' * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "            y = torch.tensor([], dtype=torch.long, device=device)\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
    "                y = torch.cat([y, val_labels], dim=0)\n",
    "            y_onehot = [to_onehot(i) for i in y]\n",
    "            y_pred_act = [act(i) for i in y_pred]\n",
    "            auc_metric(y_pred_act, y_onehot)\n",
    "            auc_result = auc_metric.aggregate()\n",
    "            auc_metric.reset()\n",
    "            del y_pred_act, y_onehot\n",
    "            metric_values.append(auc_result)\n",
    "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
    "            if acc_metric > best_metric:\n",
    "                best_metric = acc_metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
    "                print('saved new best metric model')\n",
    "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
    "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
    "                  f\" at epoch: {best_metric_epoch}\")\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_clients = 2 \n",
    "local_epochs = 2  \n",
    "communication_rounds = 10  \n",
    "\n",
    "global_model = CustomDenseNet121(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=num_class\n",
    ").to(device)\n",
    "\n",
    "# Federated learning loop\n",
    "for comm_round in range(communication_rounds):\n",
    "    print(f\"Communication Round {comm_round + 1}/{communication_rounds}\")\n",
    "    local_models = []  \n",
    "    \n",
    "    for client_id in range(num_clients):\n",
    "        print(f\"Training Local Model on Client {client_id + 1}/{num_clients}\")\n",
    "        local_model = CustomDenseNet121(\n",
    "            spatial_dims=2,\n",
    "            in_channels=3,\n",
    "            out_channels=num_class\n",
    "        ).to(device)\n",
    "        local_model.load_state_dict(global_model.state_dict()) \n",
    "        \n",
    "        for epoch in range(local_epochs):\n",
    "            local_model.train()\n",
    "            for batch_data in train_loader:\n",
    "                inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = local_model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        local_models.append(local_model)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for global_param, local_params in zip(global_model.parameters(), zip(*[local_model.parameters() for local_model in local_models])):\n",
    "            global_param.data = torch.stack(local_params).mean(dim=0)\n",
    "    \n",
    "    \n",
    "    global_model.eval()\n",
    "    test_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            outputs = global_model(inputs)\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            correct_predictions = torch.sum(predictions == labels)\n",
    "            test_accuracy += correct_predictions.item()\n",
    "    \n",
    "    test_accuracy /= len(test_loader.dataset)\n",
    "    print(f\"Test Accuracy after Communication Round {comm_round + 1}: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
